{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain of Verification Tests\n",
    "This notebook loads `Streamlit_app/llm_extractor_pipeline .py` and drives the `llm_extractor` helper with the `chain_of_verification` flag enabled.\n",
    "It focuses on validating the multi-step reasoning logic without needing to talk to a live Ollama server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook structure\n",
    "1. Import the pipeline module directly from its path.\n",
    "2. Provide lightweight stand-ins for the data loader and conversational history wrapper.\n",
    "3. Feed canned responses through `_run_chain_of_verification` and inspect the resulting dataframe payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "PIPELINE_PATH = PROJECT_ROOT / \"Streamlit_app\" / \"llm_extractor_pipeline .py\"\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"llm_pipeline\", PIPELINE_PATH)\n",
    "llm_pipeline = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"llm_pipeline\"] = llm_pipeline\n",
    "spec.loader.exec_module(llm_pipeline)\n",
    "\n",
    "llm_pipeline.llm_extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from contextlib import contextmanager\n",
    "from unittest.mock import patch\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "class SimpleFilteredData:\n",
    "    \"\"\"Mimic the Spark dataframe expected by llm_extractor.\"\"\"\n",
    "\n",
    "    def __init__(self, text: str):\n",
    "        self._text = text\n",
    "\n",
    "    def collect(self):\n",
    "        return self\n",
    "\n",
    "    def to_pandas(self):\n",
    "        return pd.DataFrame([{\"text\": self._text}])\n",
    "\n",
    "@contextmanager\n",
    "def mock_chain_of_verification(responses):\n",
    "    \"\"\"Replace the conversational runnable and model loader with canned responses.\"\"\"\n",
    "\n",
    "    class DummyConversation:\n",
    "        def __init__(self, *_args, **_kwargs):\n",
    "            self._responses = list(responses)\n",
    "            self._cursor = 0\n",
    "\n",
    "        def invoke(self, payload, config=None):\n",
    "            if self._cursor >= len(self._responses):\n",
    "                raise RuntimeError(\"No more canned responses left for the mock conversation.\")\n",
    "            value = self._responses[self._cursor]\n",
    "            self._cursor += 1\n",
    "            return value\n",
    "\n",
    "    with patch.object(llm_pipeline, \"RunnableWithMessageHistory\", DummyConversation),          patch.object(llm_pipeline, \"load_model_ollama\", lambda *args, **kwargs: object()):\n",
    "        yield\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_note = \"\"\"Patient de 58 ans consultant pour douleur thoracique constrictive depuis 2 heures.\n",
    "Pas de fièvre mais légère dyspnée à l'effort et antécédent de tabagisme arrêté depuis 5 ans.\"\"\"\n",
    "\n",
    "filtered_data = SimpleFilteredData(clinical_note)\n",
    "messages = [\n",
    "    SystemMessage(content=\"Tu es un assistant clinique qui extrait des concepts médicaux structuré en JSON.\"),\n",
    "    HumanMessage(content=\"Identifie quatre concepts clé du texte fourni, renvoie uniquement la liste JSON conforme au schéma concept/context/presence. Le compte rendu: {cr_medical}\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_response = \"\"\"Voici la structure demandée :\n",
    "[\n",
    "  {\"concept\": \"douleur thoracique\", \"context\": \"Episode aigu décrit dans l'introduction\", \"presence\": true},\n",
    "  {\"concept\": \"dyspnée\", \"context\": \"Essoufflement à l'effort mentionné paragraphe 2\", \"presence\": true},\n",
    "  {\"concept\": \"fièvre\", \"context\": \"Absence de fièvre signalée explicitement\", \"presence\": false},\n",
    "  {\"concept\": \"tabagisme\", \"context\": \"Arrêt depuis 5 ans\", \"presence\": false}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "analysis_response = \"\"\"Je vérifie concept par concept :\n",
    "- Douleur thoracique confirmée par la première phrase.\n",
    "- Dyspnée décrite comme légère.\n",
    "- Fièvre explicitement absente => présence = false.\n",
    "- Tabagisme arrêté => concept présent mais absence actuelle.\n",
    "Toutes les entrées respectent le schéma demandé.\"\"\"\n",
    "\n",
    "final_response = \"\"\"Reproduction stricte :\n",
    "[\n",
    "  {\"concept\": \"douleur thoracique\", \"context\": \"Douleur constrictive aiguë\", \"presence\": true},\n",
    "  {\"concept\": \"dyspnée\", \"context\": \"Essoufflement d'effort léger\", \"presence\": true},\n",
    "  {\"concept\": \"fièvre\", \"context\": \"Aucune élévation thermique constatée\", \"presence\": false},\n",
    "  {\"concept\": \"tabagisme\", \"context\": \"Arrêt du tabac il y a 5 ans\", \"presence\": false}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "with mock_chain_of_verification([initial_response, analysis_response, final_response]):\n",
    "    result_df = llm_pipeline.llm_extractor(\n",
    "        messages=messages,\n",
    "        filtered_data=filtered_data,\n",
    "        model_name=\"llama3.1\",\n",
    "        num_ctx=4096,\n",
    "        max_output=512,\n",
    "        temperature=0.2,\n",
    "        top_p=0.9,\n",
    "        top_k=40,\n",
    "        max_retries=1,\n",
    "        chain_of_verification=True,\n",
    "    )\n",
    "\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = pd.DataFrame(result_df.loc[0, \"concept_extracted\"])\n",
    "logs = result_df.loc[0, \"brut_response\"]\n",
    "print(\"Concepts structurés :\")\n",
    "display(concepts)\n",
    "print(\"\n",
    "Journal de la chaîne de vérification :\")\n",
    "print(logs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}